## ğŸ“‹ Objectif
Mise en place d'un cluster Big Data complet avec Docker, incluant :
- **Hadoop HDFS** pour le stockage distribuÃ©
- **YARN** pour la gestion des ressources
- **Spark** pour le traitement distribuÃ©

## ğŸ“¸ RÃ©sultats obtenus

### 1. Interface Hadoop HDFS
![Hadoop HDFS Interface](screenshots/hadoop/hadoop.png)
*Interface web du NameNode montrant le systÃ¨me de fichiers HDFS*

### 2. Interface YARN ResourceManager  
![YARN ResourceManager](screenshots/yarn/Yarn.png)
*YARN gÃ©rant l'allocation des ressources sur le cluster*

### 3. Interface Spark Master
![Spark Master](screenshots/spark/Spark.png)
*Spark Master avec les workers connectÃ©s et jobs en cours*

## ğŸ—ï¸ Architecture dÃ©ployÃ©e
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cluster Docker â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Hadoop â”‚ â”‚ YARN â”‚ â”‚
â”‚ â”‚ NameNode â”‚ â”‚ Resource â”‚ â”‚
â”‚ â”‚ Port â”‚ â”‚ Manager â”‚ â”‚
â”‚ â”‚ 9870 â”‚ â”‚ 8088 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Spark â”‚ â”‚ Node â”‚ â”‚
â”‚ â”‚ Master â”‚ â”‚ Managers â”‚ â”‚
â”‚ â”‚ 8080 â”‚ â”‚ (Workers) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

text

## ğŸ”§ Travail rÃ©alisÃ©

### Phase 1 : Installation Docker
```bash
# Configuration du cluster avec docker-compose
docker-compose up -d
Services dÃ©ployÃ©s :

âœ… Hadoop NameNode (HDFS)

âœ… YARN ResourceManager

âœ… Spark Master

âœ… 2x Spark Workers / YARN NodeManagers

âœ… 2x Hadoop DataNodes

Phase 2 : Configuration
Hadoop : Configuration HDFS avec rÃ©plication (facteur 2)

YARN : Allocation mÃ©moire (4GB total) et CPU

Spark : IntÃ©gration avec YARN comme master

RÃ©seau : Communication entre conteneurs Docker

Phase 3 : Validation
âœ… AccÃ¨s aux 3 interfaces web

âœ… Connexion entre tous les services

âœ… Soumission de jobs Spark rÃ©ussie

âœ… Stockage HDFS fonctionnel

ğŸ“Š Commandes exÃ©cutÃ©es
bash
# 1. DÃ©marrer le cluster
docker-compose up -d

# 2. VÃ©rifier l'Ã©tat des services
docker-compose ps

# 3. Tester Hadoop
hdfs dfsadmin -report

# 4. Tester YARN
yarn node -list

# 5. Soumettre un job Spark
spark-submit --master yarn --deploy-mode cluster app.py

# 6. AccÃ©der aux interfaces
# Hadoop : http://localhost:9870
# YARN   : http://localhost:8088  
# Spark  : http://localhost:8080
ğŸ“ Structure du projet
text
TP_BIGDATA_FINAL/
â”œâ”€â”€ README.md              # Documentation principale
â”œâ”€â”€ docker-compose.yml     # Configuration du cluster
â”œâ”€â”€ spark-defaults.conf    # Configuration Spark
â”œâ”€â”€ screenshots/           # Captures d'Ã©cran
â”‚   â”œâ”€â”€ hadoop/hadoop.png
â”‚   â”œâ”€â”€ yarn/Yarn.png
â”‚   â””â”€â”€ spark/Spark.png
â”œâ”€â”€ notebooks/             # Notebooks d'analyse
â”œâ”€â”€ data/                  # Jeux de donnÃ©es
â”œâ”€â”€ scripts/               # Scripts utilitaires
â””â”€â”€ docker_config/         # Fichiers de config avancÃ©s
âœ… Validation technique
Service	Port	Statut	Commentaire
Hadoop HDFS	9870	âœ… OK	NameNode accessible
YARN RM	8088	âœ… OK	ResourceManager actif
Spark Master	8080	âœ… OK	Master avec 2 workers
Spark History	18080	âœ… OK	Historique des jobs
Hadoop DataNodes	9864	âœ… OK	2 nodes connectÃ©s
ParamÃ¨tres de configuration :

MÃ©moire totale : 4 GB RAM

CÅ“urs CPU : 4

Stockage HDFS : 100 GB (rÃ©pliquÃ© x2)

RÃ©plication HDFS : facteur 2

ğŸ“ Apprentissages
Technique
Orchestration Docker : Gestion multi-conteneurs avec docker-compose

Architecture Hadoop : Interaction HDFS + YARN

Spark on YARN : ExÃ©cution de jobs Spark via YARN

Monitoring : Utilisation des interfaces web pour le suivi

Pratique
Configuration rÃ©seau entre conteneurs

Allocation dynamique des ressources

Gestion des volumes persistants

DÃ©bogage des services distribuÃ©s

ğŸ‘¨â€ğŸ’» Auteur
Youssef Bentaher
Ã‰tudiant en Big Data
AnnÃ©e universitaire 2025/2026

Ce TP a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours de Big Data.
L'ensemble du code et des configurations est disponible sous licence MIT.
