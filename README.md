# ğŸš€ TP BIG DATA - Cluster Hadoop, YARN & Spark avec Google Colab

## ğŸ“‹ Description complÃ¨te
Ce TP a pour objectif de mettre en place un cluster Big Data complet avec Docker, incluant Hadoop HDFS, YARN et Spark, et d'effectuer des analyses de donnÃ©es avec PySpark sur Google Colab.

## ğŸ“¸ Captures d'Ã©cran des interfaces

### 1. Interface Hadoop HDFS NameNode
![Hadoop HDFS Interface](screenshots/hadoop/hadoop.png)
*Interface web du NameNode montrant l'Ã©tat du systÃ¨me de fichiers distribuÃ© HDFS*

### 2. Interface YARN ResourceManager
![YARN ResourceManager Interface](screenshots/yarn/Yarn.png)
*YARN gÃ©rant l'allocation des ressources CPU et mÃ©moire sur le cluster*

### 3. Interface Spark Master
![Spark Master Interface](screenshots/spark/Spark.png)
*Spark Master avec les workers connectÃ©s et les applications en cours d'exÃ©cution*

## ğŸ”¬ Partie Google Colab - Analyses PySpark

### Notebook d'analyse disponible :
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUSSEF-BT/BIGDATA_LAB_cluster_spark/blob/main/colab_notebooks/TP_Cluster_spark_colab.ipynb)

### ğŸ““ Notebook principal : `TP_Cluster_spark_colab.ipynb`

**Contenu du notebook :**
1. **Installation et configuration** de PySpark sur Google Colab
2. **CrÃ©ation de session Spark** pour le traitement distribuÃ©
3. **Analyse de donnÃ©es** de transactions financiÃ¨res
4. **Transformations Spark** : filtrage, agrÃ©gations, jointures
5. **Visualisation** des rÃ©sultats avec Matplotlib/Seaborn

**Technologies utilisÃ©es :**
- PySpark 3.5.0
- Google Colab
- Pandas, Matplotlib, Seaborn
- Spark DataFrames

## ğŸ—ï¸ Architecture du cluster dÃ©ployÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Cluster Docker (Local)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Hadoop    â”‚  â”‚    YARN    â”‚        â”‚
â”‚  â”‚  NameNode  â”‚  â”‚ Resource   â”‚        â”‚
â”‚  â”‚  (HDFS)    â”‚  â”‚  Manager   â”‚        â”‚
â”‚  â”‚   :9870    â”‚  â”‚   :8088    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚              â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Spark     â”‚ â”‚  Spark     â”‚        â”‚
â”‚  â”‚   Master    â”‚ â”‚  Workers   â”‚        â”‚
â”‚  â”‚   :8080     â”‚ â”‚ (x2)       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Google Colab (Cloud)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Notebook PySpark           â”‚        â”‚
â”‚  â”‚  - Analyse de donnÃ©es       â”‚        â”‚
â”‚  â”‚  - Visualisations           â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Travail rÃ©alisÃ©

### Phase 1 : Installation et configuration Docker
- **Docker Compose** : DÃ©finition des services (Hadoop, YARN, Spark)
- **RÃ©seau** : Configuration de la communication entre conteneurs
- **Volumes** : Persistance des donnÃ©es HDFS
- **Services dÃ©ployÃ©s** :
  - Hadoop NameNode (port 9870)
  - YARN ResourceManager (port 8088)  
  - Spark Master (port 8080)
  - 2x Spark Workers / YARN NodeManagers
  - 2x Hadoop DataNodes

### Phase 2 : Configuration des composants
- **Hadoop HDFS** : Configuration avec rÃ©plication (facteur 2)
- **YARN** : Allocation des ressources (mÃ©moire, CPU)
- **Spark** : IntÃ©gration avec YARN comme gestionnaire de ressources
- **Environnement** : Variables d'environnement et fichiers de configuration

### Phase 3 : Analyses sur Google Colab
- **Installation PySpark** : Configuration sur l'environnement Colab
- **Session Spark** : CrÃ©ation et configuration
- **Traitement de donnÃ©es** : OpÃ©rations sur DataFrames Spark
- **Visualisation** : GÃ©nÃ©ration de graphiques

### Phase 4 : Tests et validation
- âœ… AccÃ¨s aux 3 interfaces web (Hadoop, YARN, Spark)
- âœ… Communication entre tous les services
- âœ… Soumission de jobs Spark sur YARN
- âœ… ExÃ©cution du notebook sur Colab
- âœ… Traitement et analyse de donnÃ©es

## ğŸ“Š Commandes exÃ©cutÃ©es

```bash
# 1. DÃ©marrer le cluster
docker-compose up -d

# 2. VÃ©rifier l'Ã©tat des services
docker-compose ps

# 3. Tester Hadoop HDFS
hdfs dfsadmin -report
hdfs dfs -ls /

# 4. Tester YARN
yarn node -list
yarn application -list

# 5. Soumettre un job Spark
spark-submit --master yarn --deploy-mode cluster app.py

# 6. AccÃ©der aux interfaces web
# Hadoop  : http://localhost:9870
# YARN    : http://localhost:8088  
# Spark   : http://localhost:8080

# 7. ArrÃªter le cluster
docker-compose down
```

## ğŸ“ Structure du projet

```
BIGDATA_LAB_cluster_spark/
â”œâ”€â”€ README.md                           # Documentation principale
â”œâ”€â”€ docker-compose.yml                  # Configuration du cluster Docker
â”œâ”€â”€ spark-defaults.conf                 # Configuration Spark
â”œâ”€â”€ screenshots/                        # Captures d'Ã©cran
â”‚   â”œâ”€â”€ hadoop/hadoop.png              # Interface Hadoop
â”‚   â”œâ”€â”€ yarn/Yarn.png                  # Interface YARN
â”‚   â””â”€â”€ spark/Spark.png                # Interface Spark
â”œâ”€â”€ colab_notebooks/                    # Notebooks Google Colab
â”‚   â””â”€â”€ TP_Cluster_spark_colab.ipynb   # Notebook principal PySpark
â”œâ”€â”€ docker_config/                      # Fichiers de configuration avancÃ©s
â”œâ”€â”€ notebooks/                          # Notebooks locaux
â”œâ”€â”€ scripts/                            # Scripts utilitaires
â”‚   â””â”€â”€ start_cluster.sh               # Script de dÃ©marrage
â”œâ”€â”€ data/                               # Jeux de donnÃ©es
â””â”€â”€ .gitignore                         # Fichiers ignorÃ©s par Git
```

## âœ… Validation technique

| Service | Port | Statut | Commentaire |
|---------|------|--------|-------------|
| Hadoop NameNode | 9870 | âœ… OpÃ©rationnel | Interface HDFS accessible |
| YARN ResourceManager | 8088 | âœ… OpÃ©rationnel | Gestion des ressources active |
| Spark Master | 8080 | âœ… OpÃ©rationnel | 2 workers connectÃ©s |
| Hadoop DataNodes | 9864 | âœ… OpÃ©rationnel | 2 nodes disponibles |
| Spark History Server | 18080 | âœ… OpÃ©rationnel | Historique des jobs |

**ParamÃ¨tres de configuration :**
- **MÃ©moire totale** : 4 GB RAM
- **CÅ“urs CPU** : 4
- **Stockage HDFS** : 100 GB (rÃ©pliquÃ© x2)
- **Facteur de rÃ©plication HDFS** : 2
- **Workers Spark** : 2 instances

## ğŸ“ Apprentissages et compÃ©tences acquises

### Techniques
1. **Orchestration Docker** : Gestion de clusters multi-conteneurs avec docker-compose
2. **Architecture Hadoop** : ComprÃ©hension de l'Ã©cosystÃ¨me HDFS + YARN
3. **Spark sur YARN** : ExÃ©cution de jobs Spark via le gestionnaire de ressources YARN
4. **Traitement distribuÃ©** : Utilisation de PySpark pour l'analyse de donnÃ©es Ã  grande Ã©chelle
5. **Monitoring** : Utilisation des interfaces web pour le suivi des services

### Pratiques
- Configuration rÃ©seau entre conteneurs Docker
- Allocation dynamique des ressources avec YARN
- Gestion des volumes persistants pour HDFS
- DÃ©bogage de services distribuÃ©s
- IntÃ©gration entre environnement local (Docker) et cloud (Google Colab)

## ğŸš€ DÃ©marrage rapide

### Pour le cluster Docker :
```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/YOUSSEF-BT/BIGDATA_LAB_cluster_spark.git
cd BIGDATA_LAB_cluster_spark

# DÃ©marrer le cluster
docker-compose up -d

# AccÃ©der aux interfaces :
# - Hadoop:  http://localhost:9870
# - YARN:    http://localhost:8088
# - Spark:   http://localhost:8080
```

### Pour les analyses Colab :
1. Cliquez sur le badge [![Open In Colab]](https://colab.research.google.com/github/YOUSSEF-BT/BIGDATA_LAB_cluster_spark/blob/main/colab_notebooks/TP_Cluster_spark_colab.ipynb)
2. ExÃ©cutez les cellules du notebook dans l'ordre
3. Les rÃ©sultats s'afficheront directement dans Colab

## ğŸ‘¨â€ğŸ’» Auteur
**Youssef Bouzit**  
Ã‰tudiant en Data Science  
AnnÃ©e universitaire 2025/2026

## ğŸ“§ Contact
- GitHub : [YOUSSEF-BT](https://github.com/YOUSSEF-BT)
- DÃ©pÃ´t du TP : [BIGDATA_LAB_cluster_spark](https://github.com/YOUSSEF-BT/BIGDATA_LAB_cluster_spark)

## ğŸ“„ Licence
Ce projet est disponible sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

---

*Ce TP a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours de Big Data.  
L'ensemble du code, configurations et documentations est ouvert et modifiable selon les termes de la licence MIT.*
